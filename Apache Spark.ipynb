{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading a File and Displaying Top 5 Elements:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Deforestation is arising as the main environmental and social issue which has now taken the form of more than a powerful demon.',\n",
       " 'We must know about the causes, effects and ways to solve the problems arisen because of the deforestation.',\n",
       " 'We have provided many paragraphs, long and short essay on deforestation in order to help your kids and children to get aware about the problem as well as get participated in the essay writing competition in the school or outside the school.',\n",
       " 'You can select any deforestation essay given below according to the class standard.Deforestation is arising as the major global problem to the society and environment.']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile(\"file:///Users/Georgios.Drakos/Desktop/12.txt\")\n",
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting to Lowercase and Splitting:(Lower and Split)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deforestation', 'is', 'arising', 'as', 'the']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Func(lines):\n",
    "    lines = lines.lower()\n",
    "    lines = lines.split(' ')\n",
    "    return lines\n",
    "rdd1 = rdd.flatMap(Func)\n",
    "rdd1.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removing StopWords:(Filter)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deforestation', 'arising', 'main', 'environmental', 'social']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = ['of','a','all','the','as','is','am','an','and','be','been','from','had','I','Id','why','with']\n",
    "rdd2 = rdd1.filter(lambda z: z  not in stop_words)\n",
    "rdd2.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sum of Numbers from 1 to 500: (Reduce)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124750"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_rdd = sc.parallelize(range(1,500))\n",
    "sum_rdd.reduce(lambda x,y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14157428\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "num_samples = 100000000\n",
    "def inside(p):     \n",
    "  x, y = random.random(), random.random()\n",
    "  return x*x + y*y < 1\n",
    "count = sc.parallelize(range(0, num_samples)).filter(inside).count()\n",
    "pi = 4 * count / num_samples\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "f  = urllib.request.urlretrieve('https://raw.githubusercontent.com/fivethirtyeight/data/master/'\\\n",
    "                                'daily-show-guests/daily_show_guests.csv', \"daily_show_guests.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file  = \"./daily_show_guests.csv\"\n",
    "raw_data = sc.textFile(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2694"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YEAR,GoogleKnowlege_Occupation,Show,Group,Raw_Guest_List',\n",
       " '1999,actor,1/11/99,Acting,Michael J. Fox',\n",
       " '1999,Comedian,1/12/99,Comedy,Sandra Bernhard',\n",
       " '1999,television actress,1/13/99,Acting,Tracey Ullman',\n",
       " '1999,film actress,1/14/99,Acting,Gillian Anderson']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['YEAR', 'GoogleKnowlege_Occupation', 'Show', 'Group', 'Raw_Guest_List'],\n",
       " ['1999', 'actor', '1/11/99', 'Acting', 'Michael J. Fox'],\n",
       " ['1999', 'Comedian', '1/12/99', 'Comedy', 'Sandra Bernhard'],\n",
       " ['1999', 'television actress', '1/13/99', 'Acting', 'Tracey Ullman'],\n",
       " ['1999', 'film actress', '1/14/99', 'Acting', 'Gillian Anderson']]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_show = raw_data.map(lambda line: line.split(','))\n",
    "daily_show.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[9] at RDD at PythonRDD.scala:49\n"
     ]
    }
   ],
   "source": [
    "tally = daily_show.map(lambda x: (x[0], 1)).reduceByKey(lambda x,y: x+y)\n",
    "print(tally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('YEAR', 1),\n",
       " ('2002', 159),\n",
       " ('2003', 166),\n",
       " ('2004', 164),\n",
       " ('2007', 141),\n",
       " ('2010', 165),\n",
       " ('2011', 163),\n",
       " ('2012', 164),\n",
       " ('2013', 166),\n",
       " ('2014', 163),\n",
       " ('2015', 100),\n",
       " ('1999', 166),\n",
       " ('2000', 169),\n",
       " ('2001', 157),\n",
       " ('2005', 162),\n",
       " ('2006', 161),\n",
       " ('2008', 164),\n",
       " ('2009', 163)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tally.take(tally.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_year(line):\n",
    "    if line[0] == 'YEAR':\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "filtered_daily_show = tally.filter(lambda line: filter_year(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2002', 159),\n",
       " ('2003', 166),\n",
       " ('2004', 164),\n",
       " ('2007', 141),\n",
       " ('2010', 165),\n",
       " ('2011', 163),\n",
       " ('2012', 164),\n",
       " ('2013', 166),\n",
       " ('2014', 163),\n",
       " ('2015', 100),\n",
       " ('1999', 166),\n",
       " ('2000', 169),\n",
       " ('2001', 157),\n",
       " ('2005', 162),\n",
       " ('2006', 161),\n",
       " ('2008', 164),\n",
       " ('2009', 163)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_daily_show.take(filtered_daily_show.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('actor', 596),\n",
       " ('film actress', 21),\n",
       " ('model', 9),\n",
       " ('stand-up comedian', 44),\n",
       " ('actress', 271),\n",
       " ('television personality', 13),\n",
       " ('comic', 2),\n",
       " ('musician', 19),\n",
       " ('film actor', 19),\n",
       " ('journalist', 253)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_show.filter(lambda line: line[1] != '') \\\n",
    "                   .map(lambda line: (line[1].lower(), 1))\\\n",
    "                   .reduceByKey(lambda x,y: x+y) \\\n",
    "                   .take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.141481\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "import random\n",
    "sc = SparkContext()\n",
    "num_samples = 100000000\n",
    "def inside(p):     \n",
    "  x, y = random.random(), random.random()\n",
    "  return x*x + y*y < 1\n",
    "count = sc.parallelize(range(0, num_samples)).filter(inside).count()\n",
    "pi = 4 * count / num_samples\n",
    "print(pi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
